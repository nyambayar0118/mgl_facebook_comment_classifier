{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classification with Naive Bayes\n",
    "## Монгол хэл дээрх spam/ham сэтгэгдэл ангилах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import санууд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import math\n",
    "import ssl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# HTTPS сертификатын алдааг алгасах (Google Sheets-ээс уншихад хэрэгтэй)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. N-gram болгож tokenize хийх функц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_tokenize(text, ngram_range=(2, 2)):\n",
    "    \"\"\"\n",
    "    Өгөгдсөн text-ийг үгэнд хуваагаад ngram_range=(min_n, max_n)\n",
    "    тохиргооны дагуу unigram/bigram/trigram гэх мэт жагсаалт болгож буцаана.\n",
    "    Жишээ:\n",
    "        text = \"hello world nice day\", ngram_range=(1,2)\n",
    "        -> [\"hello\", \"world\", \"nice\", \"day\",\n",
    "            \"hello world\", \"world nice\", \"nice day\"]\n",
    "    \"\"\"\n",
    "    words = text.lower().split()\n",
    "    n_min, n_max = ngram_range\n",
    "    ngrams = []\n",
    "\n",
    "    for n in range(n_min, n_max + 1):\n",
    "        if len(words) < n:\n",
    "            continue\n",
    "        for i in range(len(words) - n + 1):\n",
    "            ngram = \" \".join(words[i:i+n])\n",
    "            ngrams.append(ngram)\n",
    "\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Өөрийн бичсэн Multinomial Naive Bayes класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultinomialNB:\n",
    "    def __init__(self, alpha=1.0, ngram_range=(2, 2)):\n",
    "        # Laplace тэгшитгэлд ашиглах α параметр (smoothing)\n",
    "        self.alpha = alpha\n",
    "        # Ямар хэмжээний n-gram ашиглах (unigram, bigram, ... )\n",
    "        self.ngram_range = ngram_range\n",
    "\n",
    "        # log P(c) хадгалах dict\n",
    "        self.class_log_prior_ = {}\n",
    "        # log P(ngram | c) хадгалах dict\n",
    "        self.feature_log_probs_ = {}\n",
    "        # Нийт vocabulary (бүх ангид гарсан бүх n-gram)\n",
    "        self.vocabulary_ = set()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: текстүүдийн жагсаалт\n",
    "        y: ангиллын шошго (spam/ham)\n",
    "        \"\"\"\n",
    "        # Ангилал тус бүрийн document-ийн тоо (N_c)\n",
    "        class_counts = Counter(y)\n",
    "        total_docs = len(y)\n",
    "\n",
    "        # ----- 2.1. Приор магадлал log P(c) -----\n",
    "        for c in class_counts:\n",
    "            self.class_log_prior_[c] = math.log(class_counts[c] / total_docs)\n",
    "\n",
    "        # ----- 2.2. Ангилал тус бүрийн n-gram-ийн давтамж тоолох -----\n",
    "        class_ngram_counts = {c: Counter() for c in class_counts}  # N_{jc}\n",
    "        total_ngrams = {c: 0 for c in class_counts}                # N_c (all n-grams)\n",
    "\n",
    "        for text, label in zip(X, y):\n",
    "            ngrams = ngram_tokenize(text, self.ngram_range)\n",
    "            self.vocabulary_.update(ngrams)\n",
    "            class_ngram_counts[label].update(ngrams)\n",
    "            total_ngrams[label] += len(ngrams)\n",
    "\n",
    "        vocab_size = len(self.vocabulary_)\n",
    "\n",
    "        # ----- 2.3. Нөхцөлт магадлал θ_{jc} = P(ngram_j | class_c) -----\n",
    "        # θ_{jc} = (N_{jc} + α) / (N_c + α * V)\n",
    "        for c in class_counts:\n",
    "            self.feature_log_probs_[c] = {}\n",
    "            for ng in self.vocabulary_:\n",
    "                count = class_ngram_counts[c][ng]\n",
    "                prob = (count + self.alpha) / (total_ngrams[c] + self.alpha * vocab_size)\n",
    "                # log P(ngram | c)\n",
    "                self.feature_log_probs_[c][ng] = math.log(prob)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: текстүүдийн жагсаалт\n",
    "        Буцаах: ангиллын жагсаалт (хамгийн их posterior магадлалтай ангилал)\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for text in X:\n",
    "            ngrams = ngram_tokenize(text, self.ngram_range)\n",
    "            class_scores = {}\n",
    "\n",
    "            for c in self.class_log_prior_:\n",
    "                # Эхлээд score = log P(c)\n",
    "                score = self.class_log_prior_[c]\n",
    "\n",
    "                # Дараа нь ∑ log P(ngram | c) нэмж өгнө\n",
    "                for ng in ngrams:\n",
    "                    if ng in self.vocabulary_:\n",
    "                        score += self.feature_log_probs_[c][ng]\n",
    "\n",
    "                class_scores[c] = score\n",
    "\n",
    "            # argmax_c score(c)\n",
    "            best_class = max(class_scores, key=class_scores.get)\n",
    "            preds.append(best_class)\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Өгөгдөл унших (Google Sheets -> CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQC0C_5Sim0DhMAZbxRNxpFxBajpiHEGKeGWtSLLgbUWizbdrtoNGvv-x0P1phRr7DT6J5rCVyGzaYF/pub?output=csv'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    url,\n",
    "    engine='python',\n",
    "    on_bad_lines='skip'   # эвдэрхий мөр байвал алгасаад явна\n",
    ")\n",
    "\n",
    "# df_raw нь бүх баганатай үндсэн дата (визуализацид ашиглах)\n",
    "df_raw = df.copy()\n",
    "\n",
    "# Эхний мөрийг header болгож, iloc[0]-ийг баганын нэрэнд ашиглаж байна\n",
    "df_raw.columns = df_raw.iloc[0].astype(str).str.strip()\n",
    "df_raw = df_raw.iloc[1:]  # эхний мөрийг өгөгдлөөс хасна\n",
    "\n",
    "# label-уудыг жижиг үсгээр, зайгүй болгож цэвэрлэх\n",
    "df_raw['label'] = df_raw['label'].str.strip().str.lower()\n",
    "\n",
    "print(f\"Нийт мөрүүд: {len(df_raw)}\")\n",
    "print(f\"Label тархалт:\\n{df_raw['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Классфикаторын хувьд хэрэгтэй багануудыг тусад нь авах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = df_raw[['label', 'Raw comment']].dropna()\n",
    "df_clf = df_clf.rename(columns={'Raw comment': 'raw_comment'})\n",
    "\n",
    "X = df_clf['raw_comment']\n",
    "y = df_clf['label']\n",
    "\n",
    "# Train-test split (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(X_train)} мөр\")\n",
    "print(f\"Test set: {len(X_test)} мөр\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Naive Bayes model сургах (unigram + bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyMultinomialNB(alpha=1.0, ngram_range=(1, 2))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model амжилттай сургагдлаа!\")\n",
    "print(f\"Vocabulary хэмжээ: {len(model.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Тест өгөгдөл дээр таамаглал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Жишээ текстүүдийг ангилуулах\n",
    "print(\"Prediction:\", model.predict([\"Таалагдсан шүү aaa баярлалаа  \"]))\n",
    "print(\"Prediction:\", model.predict([\"Click this link to win iPhone\"]))\n",
    "\n",
    "# Үр дүн (accuracy, confusion matrix)\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = sorted(df_clf['label'].unique())\n",
    "df_cm = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"Actual {c}\" for c in labels],\n",
    "    columns=[f\"Pred {c}\" for c in labels]\n",
    ")\n",
    "print(\"\\nConfusion matrix:\\n\", df_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Визуализаци (comment length, emoji count, script type)\n",
    "### 7.1. Comment length histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Сэтгэгдлийн урт' баганыг тоон төрөлд хөрвүүлж, NaN-уудыг хаяна\n",
    "df_raw['Сэтгэгдлийн урт'] = pd.to_numeric(df_raw['Сэтгэгдлийн урт'], errors='coerce')\n",
    "# Зөвхөн label + урт байгаа мөрүүдийг авна\n",
    "df_len = df_raw[['label', 'Сэтгэгдлийн урт']].dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.histplot(\n",
    "    data=df_len,\n",
    "    x='Сэтгэгдлийн урт',\n",
    "    hue='label',          # spam / ham-ийг өнгөөр ялгана\n",
    "    bins=10,\n",
    "    multiple='dodge',     # нэг bin дээр 2 багана (spam, ham) зэрэгцүүлж зурна\n",
    "    stat='count',\n",
    "    palette={'spam': '#ffcccc', 'ham': '#ccffcc'}  # light red for spam, light green for ham\n",
    ")\n",
    "plt.title(\"Comment length distribution by class (spam vs ham)\")\n",
    "plt.xlabel(\"Сэтгэгдлийн урт (тэмдэгтүүдийн тоо)\")\n",
    "plt.ylabel(\"Давтамж\")\n",
    "\n",
    "# X тэнхлэгийн tick-үүдийг цэгцтэй болгоё\n",
    "max_len = int(df_len['Сэтгэгдлийн урт'].max())\n",
    "step = 200\n",
    "plt.xticks(range(0, max_len + step, step), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Emoji-ний тоо дээр histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Convert emoji count to numeric\n",
    "df_raw['Emoji-ний тоо'] = pd.to_numeric(df_raw['Emoji-ний тоо'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Clip extreme outlier\n",
    "df_plot = df_raw.copy()\n",
    "df_plot['Emoji-ний тоо'] = df_plot['Emoji-ний тоо'].clip(upper=10)\n",
    "\n",
    "sns.histplot(\n",
    "    data=df_plot,\n",
    "    x='Emoji-ний тоо',\n",
    "    hue='label',\n",
    "    bins=10,\n",
    "    multiple='dodge',\n",
    "    stat='count',\n",
    "    palette={'spam': '#ffcccc', 'ham': '#ccffcc'}  # light red for spam, light green for ham\n",
    ")\n",
    "\n",
    "plt.title(\"Emoji count distribution by class (spam vs ham)\")\n",
    "plt.xlabel(\"Emoji-ний тоо (≥10 → 10 гэж нэгтгэсэн)\")\n",
    "plt.ylabel(\"Давтамж\")\n",
    "# Set x ticks 0–10\n",
    "plt.xticks(range(0, 11))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Голдуу ашигласан үсэг (кирилл/латин/бусад) pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Голдуу ашигласан үсэг' баганад хэдэн төрөл байгааг тоолно\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "labels = ['spam', 'ham']\n",
    "# Define colors for different script types, using lighter/darker shades based on spam/ham\n",
    "colors_spam = ['#ff9999', '#ffcccc', '#ff6666', '#ffb3b3']  # shades of red for spam\n",
    "colors_ham = ['#99ff99', '#ccffcc', '#66ff66', '#b3ffb3']   # shades of green for ham\n",
    "colors_map = {'spam': colors_spam, 'ham': colors_ham}\n",
    "\n",
    "for i, lbl in enumerate(labels):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    \n",
    "    subset = df_raw[df_raw['label'] == lbl]\n",
    "    script_counts = subset['Голдуу ашигласан үсэг'].value_counts()\n",
    "\n",
    "    plt.pie(\n",
    "        script_counts.values,\n",
    "        labels=script_counts.index,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        colors=colors_map[lbl][:len(script_counts)]\n",
    "    )\n",
    "    plt.title(f\"Голдуу ашигласан үсэг — {lbl}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Improved Binary Feature Analysis (Balanced & Non-overlapping)\n",
    "### Баганын нэр солих ба binary features боловсруулах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column rename mapping (if needed)\n",
    "rename_map = {\n",
    "    'Зураг агуулсан эсэх': 'contains_photo',\n",
    "    'Нэрээ нууцалсан эсэх': 'is_anonymous',\n",
    "    'Монгол нэр эсэх': 'is_mongolian_name',\n",
    "    'Кирил, латин биш тэмдэгт ашигласан эсэх': 'has_weird_chars',\n",
    "    'Email агуулсан эсэх': 'contains_email',\n",
    "    'Link агуулсан эсэх': 'contains_link',\n",
    "    'Утасны дугаар агуулсан эсэх': 'contains_number'\n",
    "}\n",
    "df_raw = df_raw.rename(columns=rename_map)\n",
    "\n",
    "binary_features = [\n",
    "    'contains_photo',\n",
    "    'is_anonymous',\n",
    "    'is_mongolian_name',\n",
    "    'has_weird_chars',\n",
    "    'contains_email',\n",
    "    'contains_link',\n",
    "    'contains_number'\n",
    "]\n",
    "\n",
    "# Convert to numeric 0/1 where needed\n",
    "for col in binary_features:\n",
    "    df_raw[col] = (\n",
    "        df_raw[col].astype(str).str.strip().str.lower()\n",
    "        .replace({'yes':1, 'no':0, 'true':1, 'false':0,\n",
    "                  'тийм':1, 'үгүй':0, '1':1, '0':0})\n",
    "    )\n",
    "    df_raw[col] = pd.to_numeric(df_raw[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "print(\"Binary features боловсруулсан!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 Percent distribution (3 at a time, with count + percentage labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 3\n",
    "total_rows = len(df_raw)\n",
    "\n",
    "for start in range(0, len(binary_features), chunk_size):\n",
    "    end = start + chunk_size\n",
    "    chunk = binary_features[start:end]\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    for i, col in enumerate(chunk):\n",
    "        plt.subplot(1, len(chunk), i+1)\n",
    "\n",
    "        counts = df_raw[col].value_counts().sort_index()               \n",
    "        pct = (counts / total_rows * 100).round(2)\n",
    "\n",
    "        ax = sns.barplot(\n",
    "            x=counts.index.astype(str),\n",
    "            y=pct.values,\n",
    "            palette=[\"#ffcccc\", \"#ccffcc\"]  # 0=red, 1=green\n",
    "        )\n",
    "\n",
    "        plt.title(f\"{col} — % Distribution\", fontsize=12)\n",
    "        plt.xlabel(\"0 = No, 1 = Yes\")\n",
    "        plt.ylabel(\"Percentage (%)\")\n",
    "        plt.ylim(0, 100)\n",
    "\n",
    "        for index, value in enumerate(pct.values):\n",
    "            count_value = counts.iloc[index]\n",
    "            ax.text(\n",
    "                index,\n",
    "                value + 2,\n",
    "                f\"{value}%\\n({count_value})\",\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=10,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 Reverse Percentage: Out of comments where feature == 1, what % are spam vs ham?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 3\n",
    "\n",
    "for start in range(0, len(binary_features), chunk_size):\n",
    "    end = start + chunk_size\n",
    "    chunk = binary_features[start:end]\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    for i, col in enumerate(chunk):\n",
    "        plt.subplot(1, len(chunk), i+1)\n",
    "\n",
    "        # Filter only rows where the feature is 1\n",
    "        df_feature = df_raw[df_raw[col] == 1]\n",
    "\n",
    "        total_with_feature = len(df_feature)\n",
    "\n",
    "        if total_with_feature == 0:\n",
    "            # Avoid division by zero\n",
    "            plt.title(f\"{col} — No rows with value 1\")\n",
    "            plt.bar([\"ham\", \"spam\"], [0, 0])\n",
    "            continue\n",
    "\n",
    "        # Count spam and ham among rows with feature == 1\n",
    "        spam_count = (df_feature[\"label\"] == \"spam\").sum()\n",
    "        ham_count  = (df_feature[\"label\"] == \"ham\").sum()\n",
    "\n",
    "        spam_pct = round(spam_count / total_with_feature * 100, 2)\n",
    "        ham_pct  = round(ham_count  / total_with_feature * 100, 2)\n",
    "\n",
    "        values = [ham_pct, spam_pct]\n",
    "        labels = [\"ham\", \"spam\"]\n",
    "\n",
    "        ax = sns.barplot(\n",
    "            x=labels,\n",
    "            y=values,\n",
    "            palette={'spam': '#ffcccc', 'ham': '#ccffcc'}  # light red for spam, light green for ham\n",
    "        )\n",
    "\n",
    "        plt.title(f\"{col} — Among feature=1\", fontsize=12)\n",
    "        plt.ylabel(\"% of comments (feature=1)\")\n",
    "        plt.ylim(0, 100)\n",
    "\n",
    "        # Annotate bars\n",
    "        for idx, val in enumerate(values):\n",
    "            count_val = ham_count if idx == 0 else spam_count\n",
    "            ax.text(\n",
    "                idx,\n",
    "                val + 2,\n",
    "                f\"{val}%\\n({count_val} comments)\",\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=10,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3 Updated heatmap - Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_cols = ['Сэтгэгдлийн урт', 'Emoji-ний тоо'] + binary_features\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(\n",
    "    df_raw[heatmap_cols].corr(),\n",
    "    annot=True, fmt=\".2f\",\n",
    "    cmap=\"coolwarm\", linewidths=0.5\n",
    ")\n",
    "plt.title(\"Correlation Matrix for All Numerical & Binary Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
